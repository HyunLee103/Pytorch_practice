{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "timbreTron.ipynb",
      "provenance": [],
      "mount_file_id": "1MBDUXu2Vo-4JX_uuJFV6GBthP8lpVuWq",
      "authorship_tag": "ABX9TyMxlObAoNm92RLo6aln814s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyunLee103/Pytorch_practice/blob/master/timbreTron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX_WAaSglHr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import json\n",
        "\n",
        "json_dir = '/content/drive/Shared drives/Music_Style_Transform/json_sample'\n",
        "save_dir_b = '/content/drive/My Drive/ADV_Project_Music_style_transform/cqt_sample/bass'\n",
        "save_dir_d = '/content/drive/My Drive/ADV_Project_Music_style_transform/cqt_sample/drum'\n",
        "save_dir_o = '/content/drive/My Drive/ADV_Project_Music_style_transform/cqt_sample/other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkl44brFo4kt",
        "colab_type": "code",
        "outputId": "001ad08b-f5a3-48b3-e771-98a7702a79dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "# json -> cqt\n",
        "\n",
        "\n",
        "for i,(dirpath,dirnames,filenames) in enumerate(os.walk(json_dir)):\n",
        "    if dirpath is not json_dir:\n",
        "\n",
        "        genre = dirpath.split('/')[-1]\n",
        "        print(\"\\n Processing : {}\".format(genre))\n",
        "        \n",
        "        for index, f in enumerate(filenames):\n",
        "            file_path = os.path.join(dirpath,f)\n",
        "            id = f[1:5]\n",
        "            seg = f[6]\n",
        "            \n",
        "            print(index, f)\n",
        "\n",
        "            with open(file_path) as fp:\n",
        "                data = json.load(fp)\n",
        "                try:\n",
        "                    data = np.array(data)\n",
        "                    data = data.reshape(480000)\n",
        "                    all = np.abs(librosa.core.cqt(data, 32000))\n",
        "                    all = all[:,:,np.newaxis]\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "\n",
        "                if index % 2 != 0:\n",
        "                    with open(file_path) as fp:\n",
        "                        data = json.load(fp)\n",
        "                        data = np.array(data['wave'])\n",
        "                        for i in range(3):\n",
        "                            if i == 0:\n",
        "                                drum = data[i]\n",
        "                                drum = drum.reshape(480000)\n",
        "                                drum = np.abs(librosa.core.cqt(drum, 32000))\n",
        "                                drum = drum[:,:,np.newaxis]\n",
        "                                da = np.concatenate((drum,all),axis=2)\n",
        "                                np.save(os.path.join(save_dir_d,'{}_{}_da_{}_cqt'.format(genre,id,seg)),da)\n",
        "                            elif i == 1:\n",
        "                                bass = data[i]\n",
        "                                bass = bass.reshape(480000)\n",
        "                                bass = np.abs(librosa.core.cqt(bass, 32000))\n",
        "                                bass = bass[:,:,np.newaxis]\n",
        "                                ba = np.concatenate((bass,all),axis=2)\n",
        "                                np.save(os.path.join(save_dir_b,'{}_{}_ba_{}_cqt'.format(genre,id,seg)),ba)\n",
        "                            elif i == 2:\n",
        "                                other = data[i]\n",
        "                                other = other.reshape(480000)\n",
        "                                other = np.abs(librosa.core.cqt(other, 32000))\n",
        "                                other = other[:,:,np.newaxis]\n",
        "                                oa = np.concatenate((other,all),axis=2)\n",
        "                                np.save(os.path.join(save_dir_o,'{}_{}_oa_{}_cqt'.format(genre,id,seg)),oa)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Processing : jazz\n",
            "0 00237_0_all.json\n",
            "1 00237_0.json\n",
            "2 00237_1_all.json\n",
            "3 00237_1.json\n",
            "4 00590_0_all.json\n",
            "5 00590_0.json\n",
            "6 00590_1_all.json\n",
            "7 00590_1.json\n",
            "8 00591_0_all.json\n",
            "9 00591_0.json\n",
            "10 00591_1_all.json\n",
            "11 00591_1.json\n",
            "\n",
            " Processing : pop\n",
            "0 04064_0_all.json\n",
            "1 04064_0.json\n",
            "2 04064_1_all.json\n",
            "3 04064_1.json\n",
            "4 04065_0_all.json\n",
            "5 04065_0.json\n",
            "6 04065_1_all.json\n",
            "7 04065_1.json\n",
            "8 04066_0_all.json\n",
            "9 04066_0.json\n",
            "10 04066_1_all.json\n",
            "11 04066_1.json\n",
            "12 04067_0_all.json\n",
            "13 04067_0.json\n",
            "14 04067_1_all.json\n",
            "15 04067_1.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLk9CypQRq0N",
        "colab_type": "text"
      },
      "source": [
        "# shape : (84, 938)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIv02MerUbsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        conv_block = [  nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.ReflectionPad2d(1),\n",
        "                        nn.Conv2d(in_features, in_features, 3),\n",
        "                        nn.InstanceNorm2d(in_features)  ]\n",
        "\n",
        "        self.conv_block = nn.Sequential(*conv_block)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Initial convolution block       \n",
        "        model = [   nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(input_nc, 64, 7),\n",
        "                    nn.InstanceNorm2d(64),\n",
        "                    nn.ReLU(inplace=True) ]\n",
        "\n",
        "        # Downsampling\n",
        "        in_features = 64\n",
        "        out_features = in_features*2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features*2\n",
        "\n",
        "        # Residual blocks\n",
        "        for _ in range(n_residual_blocks):\n",
        "            model += [ResidualBlock(in_features)]\n",
        "\n",
        "        # Upsampling\n",
        "        out_features = in_features//2\n",
        "        for _ in range(2):\n",
        "            model += [  nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),\n",
        "                        nn.InstanceNorm2d(out_features),\n",
        "                        nn.ReLU(inplace=True) ]\n",
        "            in_features = out_features\n",
        "            out_features = in_features//2\n",
        "\n",
        "        # Output layer\n",
        "        model += [  nn.ReflectionPad2d(3),\n",
        "                    nn.Conv2d(64, output_nc, 7),\n",
        "                    nn.Tanh() ]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # A bunch of convolutions one after another\n",
        "        model = [   nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "                    nn.InstanceNorm2d(128), \n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "                    nn.InstanceNorm2d(256), \n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        model += [  nn.Conv2d(256, 512, 4, padding=1),\n",
        "                    nn.InstanceNorm2d(512), \n",
        "                    nn.LeakyReLU(0.2, inplace=True) ]\n",
        "\n",
        "        # FCN classification layer\n",
        "        model += [nn.Conv2d(512, 1, 4, padding=1)]\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  self.model(x)\n",
        "        # Average pooling and flatten\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGdfIGWfVAv0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "outputId": "700dfe0d-d6bc-420a-da1b-4ef80cf5bf69"
      },
      "source": [
        "!pip install visdom"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting visdom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\r\u001b[K     |▌                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 4.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 4.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 389kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 419kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 450kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 471kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 481kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 501kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 512kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 532kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 563kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 583kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 624kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 645kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 665kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.6/dist-packages (from visdom) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom) (4.5.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom) (19.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom) (1.12.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/82/53/73ca86f2a680c705dcd1708be4887c559dfe9ed250486dd3ccd8821b8ccb/jsonpatch-1.25-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from visdom) (7.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom) (2020.4.5.1)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655250 sha256=fb0941717707c06153137bea9cbd97c4fd117e75f5e56bc4486013772ef0370f\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5712 sha256=4e42711f631c3627a74f27d135a5359aaa529af4b32735ecec616d7c23bf9bd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed jsonpatch-1.25 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vio0QIoU992",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transforms.Compose(transform_)\n",
        "        #self.unaligned = unaligned # ??\n",
        "\n",
        "        lst_data = os.listdir(self.data_dir)\n",
        "        self.lst_data_jazz = [f for f in lst_data if f.startswith('j')]\n",
        "        self.lst_data_pop = [f for f in lst_data if f.startswith('p')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.lst_data_jazz), len(self.lst_data_jazz))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        jazz = np.load(os.path.join(self.data_dir,self.lst_data_jazz[index]))\n",
        "        pop = np.load(os.path.join(self.data_dir,self.lst_data_pop[index]))\n",
        "        \n",
        "        if self.transform:\n",
        "            jazz = self.transform(jazz)\n",
        "            pop = self.transform(pop)\n",
        "        \n",
        "        return {'jazz': jazz, 'pop': pop}\n",
        "\n",
        "## 트렌스폼 구현하기\n",
        "class ToTensor(object):\n",
        "    def __call__(self, data):\n",
        "        for key, value in data.items():\n",
        "            value = value.transpose((2, 0, 1)).astype(np.float32)\n",
        "            data[key] = torch.from_numpy(value)\n",
        "\n",
        "        return data\n",
        "\n",
        "class Normalization(object):\n",
        "    def __init__(self, mean=0.5, std=0.5):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, data):\n",
        "        for key, value in data.items():\n",
        "            data[key] = (value - self.mean) / self.std\n",
        "\n",
        "        return data\n",
        "\n",
        "\n",
        "\n",
        "# DCGAN에 사용할 selanA image data가 DCGAN 모델의 generator output인 64x64와 맞지 않으므로\n",
        "# resize 해주는 transform class 선언\n",
        "class Resize(object):\n",
        "    def __init__(self,shape):\n",
        "        self.shape = shape\n",
        "\n",
        "    def __call__(self, data):\n",
        "        for key, value in data.items():\n",
        "            data[key] = resize(value, output_shape=(self.shape[0],self.shape[1],\n",
        "                                                    self.shape[2]))\n",
        "        return data\n",
        "\n",
        "class RandomCrop(object):\n",
        "  def __init__(self, shape):\n",
        "      self.shape = shape\n",
        "\n",
        "  def __call__(self, data):\n",
        "    # input, label = data['input'], data['label']\n",
        "    # h, w = input.shape[:2]\n",
        "\n",
        "    h, w = data['label'].shape[:2]\n",
        "    new_h, new_w = self.shape\n",
        "\n",
        "    top = np.random.randint(0, h - new_h)\n",
        "    left = np.random.randint(0, w - new_w)\n",
        "\n",
        "    id_y = np.arange(top, top + new_h, 1)[:, np.newaxis]\n",
        "    id_x = np.arange(left, left + new_w, 1)\n",
        "\n",
        "    # input = input[id_y, id_x]\n",
        "    # label = label[id_y, id_x]\n",
        "    # data = {'label': label, 'input': input}\n",
        "\n",
        "    # Updated at Apr 5 2020\n",
        "    for key, value in data.items():\n",
        "        data[key] = value[id_y, id_x]\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTWS68z4ksT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/ADV_Project_Music_style_transform/timbreTron_cycleGAN/cqt_sample/bass'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKVbMY-hj_hJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_ = [transforms.ToTensor(),transforms.Normalize((0.5,0.5),(0.5,0.5))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id1e8NGVj40b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader = DataLoader(Dataset(data_dir, transform=transform_),batch_size=3,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtEYepyem7Fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM7OXxV8lBpX",
        "colab_type": "code",
        "outputId": "42cb9888-7e28-4068-f341-15b8a6b56468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        }
      },
      "source": [
        "for i, data in enumerate(dataloader):\n",
        "    real_j = data['jazz'].to(device)\n",
        "    real_p = data['pop'].to(device)\n",
        "    print(real_p.shape,real_j.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 84, 938]) torch.Size([3, 2, 84, 938])\n",
            "torch.Size([3, 2, 84, 938]) torch.Size([3, 2, 84, 938])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BaQWp5plMuu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DECBR2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, norm=\"bnorm\", relu=0.0,output_padding=0):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        layers += [nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                             kernel_size=kernel_size, stride=stride, padding=padding, output_padding = output_padding,\n",
        "                             bias=bias)]\n",
        "\n",
        "        if not norm is None:\n",
        "            if norm == \"bnorm\":\n",
        "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
        "            elif norm == \"inorm\":\n",
        "                layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "\n",
        "        if not relu is None and relu >= 0.0:\n",
        "            layers += [nn.ReLU() if relu == 0 else nn.LeakyReLU(relu)]\n",
        "\n",
        "        self.cbr = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cbr(x)\n",
        "\n",
        "class CBR2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True, norm=\"bnorm\", relu=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                             kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                             bias=bias)]\n",
        "\n",
        "        if not norm is None:\n",
        "            if norm == \"bnorm\":\n",
        "                layers += [nn.BatchNorm2d(num_features=out_channels)]\n",
        "            elif norm == \"inorm\":\n",
        "                layers += [nn.InstanceNorm2d(num_features=out_channels)]\n",
        "\n",
        "        if not relu is None and relu >= 0.0:\n",
        "            layers += [nn.ReLU() if relu == 0 else nn.LeakyReLU(relu)]\n",
        "\n",
        "        self.cbr = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cbr(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hebrdBorh1QB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Pix2Pix_generator(nn.Module):\n",
        "    def __init__(self, in_channels,out_channels,nker=64,norm='bnorm'):\n",
        "        super(Pix2Pix_generator, self).__init__()\n",
        "\n",
        "        # encoder\n",
        "        # Leaky relu 사용, 첫번째 encoder는 batchnorm X\n",
        "        self.enc1 = CBR2d(in_channels,1*nker,kernel_size=4, padding=1,stride=2,\n",
        "        norm = None,relu=0.2)\n",
        "        self.enc2 = CBR2d(1*nker,2*nker,kernel_size=4, padding=1,stride=2,\n",
        "        norm = norm ,relu=0.2)\n",
        "        self.enc3 = CBR2d(2*nker,4*nker,kernel_size=4, padding=1,stride=2,\n",
        "        norm = norm,relu=0.2)\n",
        "        self.enc4 = CBR2d(4*nker,8*nker,kernel_size=4, padding=1,stride=2,\n",
        "        norm = norm,relu=0.2)\n",
        "        self.enc5 = CBR2d(8*nker,8*nker,kernel_size=4, padding=1,stride=2,\n",
        "        norm = norm,relu=0.2)\n",
        "        self.enc6 = CBR2d(8*nker,8*nker,kernel_size=4, padding=1,stride=2,\n",
        "        norm = norm,relu=0.2)\n",
        "\n",
        "\n",
        "        # decoder, skip-connection 고려해서 input channel modeling\n",
        "        self.dec1 = DECBR2d(8*nker, 8*nker, kernel_size=4, padding=1,\n",
        "        norm = norm, relu=0.0, stride=2)\n",
        "        self.drop1 = nn.Dropout2d(0.5)\n",
        "        self.pad1 = nn.ReflectionPad2d((0,1,0,0)) # (left, right, top, bottom) \n",
        "        \n",
        "        self.dec2 = DECBR2d(2 * 8 * nker, 8*nker, kernel_size=4, padding=1,\n",
        "        norm = norm, relu=0.0, stride=2)\n",
        "        self.drop2 = nn.Dropout2d(0.5)\n",
        "        self.pad2 = nn.ReflectionPad2d((0,0,0,1))\n",
        "\n",
        "        self.dec3 = DECBR2d(2*8*nker, 4*nker, kernel_size=4, padding=1,\n",
        "        norm = norm, relu=0.0, stride=2)\n",
        "        self.drop3 = nn.Dropout2d(0.5)\n",
        "        self.pad3 = nn.ReflectionPad2d((1,0,0,0))\n",
        "\n",
        "        self.dec4 = DECBR2d(2 * 4 *nker, 2*nker, kernel_size=4, padding=1,\n",
        "        norm = norm, relu=0.0, stride=2)\n",
        "        self.pad4 = nn.ReflectionPad2d((0,0,1,0))\n",
        "\n",
        "        self.dec5 = DECBR2d(2*2*nker, 1*nker, kernel_size=4, padding=1,\n",
        "        norm = norm, relu=0.0, stride=2)\n",
        "        self.pad5 = nn.ReflectionPad2d((1,0,0,0))\n",
        "        \n",
        "        self.dec6 = DECBR2d(2*1*nker, out_channels, kernel_size=4, padding=1,\n",
        "        norm = None, relu=None, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.shape)\n",
        "        enc1 = self.enc1(x)\n",
        "        print(enc1.shape)\n",
        "        enc2 = self.enc2(enc1)\n",
        "        print(enc2.shape)\n",
        "        enc3 = self.enc3(enc2)\n",
        "        print(enc3.shape)\n",
        "        enc4 = self.enc4(enc3)\n",
        "        print(enc4.shape)\n",
        "        enc5 = self.enc5(enc4)\n",
        "        print(enc5.shape)\n",
        "        enc6 = self.enc6(enc5)\n",
        "        print(enc6.shape)\n",
        "     \n",
        "\n",
        "        dec1 = self.dec1(enc6)\n",
        "        drop1 = self.drop1(dec1)\n",
        "        pad1 = self.pad1(drop1)\n",
        "        print(pad1.shape)\n",
        "\n",
        "        cat2 = torch.cat((pad1,enc5),dim=1)\n",
        "        dec2 = self.dec2(cat2)\n",
        "        drop2 = self.drop2(dec2)\n",
        "        pad2 = self.pad2(drop2)\n",
        "        print(pad2.shape)\n",
        "\n",
        "        cat3 = torch.cat((pad2,enc4),dim=1)\n",
        "        dec3 = self.dec3(cat3)\n",
        "        drop3 = self.drop3(dec3)\n",
        "        pad3 = self.pad3(drop3)\n",
        "        print(pad3.shape)\n",
        "\n",
        "        cat4 = torch.cat((pad3,enc3),dim=1)\n",
        "        print(cat4.shape)\n",
        "        dec4 = self.dec4(cat4)\n",
        "        pad4 = self.pad4(dec4)\n",
        "        print(pad4.shape)\n",
        "\n",
        "        cat5 = torch.cat((pad4,enc2),dim=1)\n",
        "        dec5 = self.dec5(cat5)\n",
        "        pad5 = self.pad5(dec5)\n",
        "        print(pad5.shape)\n",
        "\n",
        "        cat6 = torch.cat((pad5,enc1),dim=1)\n",
        "        dec6 = self.dec6(cat6)\n",
        "       \n",
        "      \n",
        "        x = torch.tanh(dec6)\n",
        "        print(x.shape)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwDW1C2Macy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Pix2Pix_generator(2,2,norm='inorm').to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQLUTO1Pac2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "24a603b8-3cea-4a4c-e141-6308f3cd3926"
      },
      "source": [
        "out = net(real_j.float())"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 84, 938])\n",
            "torch.Size([3, 64, 42, 469])\n",
            "torch.Size([3, 128, 21, 234])\n",
            "torch.Size([3, 256, 10, 117])\n",
            "torch.Size([3, 512, 5, 58])\n",
            "torch.Size([3, 512, 2, 29])\n",
            "torch.Size([3, 512, 1, 14])\n",
            "torch.Size([3, 512, 2, 29])\n",
            "torch.Size([3, 512, 5, 58])\n",
            "torch.Size([3, 256, 10, 117])\n",
            "torch.Size([3, 512, 10, 117])\n",
            "torch.Size([3, 128, 21, 234])\n",
            "torch.Size([3, 64, 42, 469])\n",
            "torch.Size([3, 2, 84, 938])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voFJA28W6qWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "1cb7c1b1-8784-4685-eb49-12bcfa68619c"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 84, 938])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhmsMEeMac5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slpQcJH_qVgD",
        "colab_type": "code",
        "outputId": "6b451571-1a96-425b-ee13-ab0376e1c5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Networks\n",
        "netG_A2B = Generator(2, 2).to(device)\n",
        "netG_B2A = Generator(2, 2).to(device)\n",
        "netD_A = Discriminator(2).to(device)\n",
        "netD_B = Discriminator(2).to(device)\n",
        "\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "# Lossess\n",
        "criterion_GAN = torch.nn.MSELoss().to(device)\n",
        "criterion_cycle = torch.nn.L1Loss().to(device)\n",
        "criterion_identity = torch.nn.L1Loss().to(device)\n",
        "\n",
        "# Optimizers & LR schedulers\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
        "                                lr=opt.lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-340-0fff13fe7363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Optimizers & LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n\u001b[0;32m---> 19\u001b[0;31m                                 lr=opt.lr, betas=(0.5, 0.999))\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0moptimizer_D_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0moptimizer_D_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc65d97BrHRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}